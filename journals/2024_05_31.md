- [[question]]
	- Question about the $I_{det, t1}$ when calculating [[attenuation]]
	  logseq.order-list-type:: number
		- ![image.png](../assets/image_1717141106242_0.png)
		- I saw some resources mentioned that baseline value, $I_{det, t1}$ is commonly calculated by averaging [[light intensity]] over entire scan.
		- ![image.png](../assets/image_1717141292754_0.png)
		- When I refer to the provided Matlab code, $I_{det, t1}$ is calculated based on the average light intensity of the first five timestamps. I understand that the value of $I_{det, t1}$ isn't very significant since [[dMBLL]] calculates the changes in HbO concentration. However, won't this affect the results when comparing [[GLM]] outcomes between different brain areas, since the [[cHRF]] starts at an ideal baseline value while the HbO concentration doesn't start at a true baseline value? Or does this code assume that the brain activity during the first five timestamps is at rest (baseline value)?
		- Also, I understood that $m==0$ and $bc==0$ are to avoid error from division by zero, but won't this also affect the baseline value of HbO?
	- How the order, low and high cutoff frequency are determined?
	  logseq.order-list-type:: number
		-