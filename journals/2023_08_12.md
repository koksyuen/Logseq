- [[RL]] [[math]] 
  [[return]] : cummulative future reward
  ![image.png](../assets/image_1691825289676_0.png)
  [[value function]] 
  $E_A$: expectation w.r.t action $a_t \sim \pi(.|s_t)$
  ![image.png](../assets/image_1691820113278_0.png) ![image.png](../assets/image_1691820248827_0.png)
  [[optimal action-value function]]
  $$Q*(a, s)=\max_{\pi}Q_{\pi}(a, s)$$
- [[math]] [[RL]] 
  [[random sampling]]
  **~** means 'sampling from' 
  **.** denotes variable that was sampled
  ![image.png](../assets/image_1691820728529_0.png)
- [[math]] [[RL]] ![image.png](../assets/image_1691822540004_0.png)
- [[math]] [[RL]] 
  Probability Distribution Function [[PDF]]
  ![image.png](../assets/image_1691823781424_0.png)
- [[math]] [[RL]]
  [[Expectation]]
  ![image.png](../assets/image_1691823893269_0.png)
- [[math]][[RL]] 
  Policy function
  ![image.png](../assets/image_1691824420623_0.png)
- [[math]] [[RL]]
  state transition
  ![image.png](../assets/image_1691824508353_0.png)