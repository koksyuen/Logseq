alias:: 共融, socially aware navigation, social navigation，co-exist, socially acceptable, social comfort

- literature review
  collapsed:: true
	- [[psychology]]
		- [[@holmanWatchWhereYou2021]]
		- [[@munOcclusionAwareCrowdNavigation2022]]
	- [[GNN]]
		- [[Trajectory Prediction]]
			- [[@yuSpatiotemporalGraphTransformer2020]]
			- [[@huangLearningSparseInteraction2022]]
		- [[Reinforcement Learning]]
			- Prediction-based
				- [[@liuIntentionAwareRobot2022]]
				- [[@chenRelationalGraphLearning2020]]
			- Non-prediction based
				- [[@chenRobotNavigationCrowds2020]]
	- [[Trajectory Prediction]]
	  collapsed:: true
		- [[@liuSocialNCEContrastive2021]]
		- [[@sunMoveTrajectoriesDistribution2021]]
	- [[Reinforcement Learning]]
		-
	- [[experiment]]
		- [[evaluation]]
		- [[simulation]]
- 昇腾AI创新大赛昇腾AI创新大赛
  id:: 65037810-4567-4f4d-9e98-46c7092e78c6
  collapsed:: true
	- 近年来，机器人在人机交互社交环境中得到了广泛应用。无论是在公共场所还是社交活动中，我们都能越来越常见地看到机器人的身影。它们可以是引导参观者的服务机器人，也可以是与会议参与者互动交流的机器人伴侣。在这样广泛的应用中，机器人能够深入理解人类社交规范和个人边界，并在人类环境中自如地导航，这对于人与机器人之间的和谐共处至关重要。实际上，实现机器人与人类之间无缝和谐互动的关键在于机器人展现出具备一定的社交意识的行为能力。一个具备社交意识的机器人应该能够理解和适当地回应人类的线索、表情和意图，从而在人类中树立信任。然而，挑战在于人类社交动态的内在复杂性，其中包含了众多未明确规定的规则、文化上的微妙差异和个体偏好。
	  反过来，社交意识导航成为机器人在人机交互环境中部署的关键挑战。特别是，社交意识导航是一个流行的新兴研究课题，它融合了机器人感知、人机交互和路径规划等领域。事实上，许多传统的路径规划方法无法有效处理人口密集环境中的导航挑战，因为它们忽视了智能实体（如人类）的存在。相比之下，具备社交意识的机器人应该能够通过观察环境并有目的地行动，对周围环境进行认知，以改善人类的舒适度和安全感，将人类视为社会主体而非简单的障碍物。这需要机器人能够认知周围环境并作出相应的行动。这个领域的研究正不断发展，以实现机器人和人类之间更加和谐和自然的互动。
	- 为了确保人与机器人之间的和谐共存，机器人在人群中导航时对社会规范以及个人边界的理解就显得尤为重要。为此，我们提出了一种基于强化学习的社交感知机器人导航框架。该框架考虑了行人的情绪，并使用基于情感的邻近奖励函数来指导机器人的行为。此外，此外，我们还引入了一种名为个人空间地图的新型信息融合方式，该方法结合了预测的人类意图和基于情感的个人空间，并作为强化学习策略的观测值。实验结果表明，我们的框架使机器人能够在人群中导航，而不会引起行人的不适，同时也确保了高效的路径规划。
	- 研究结果表明，将人的情感因素考虑纳入到路径规划的算法中，可以明显提高策略规划的效率，特别是在封闭环境中有大量人群的情况下。此外，将人的情感因素融入到导航策略中，还可以促使机器人在导航过程中更符合社交习惯，从而进一步提升人们的舒适感。
- chinese
  id:: 65031735-509b-429f-bc63-5b9aa8671de8
  collapsed:: true
	- abstract
		- 基于人类情感和意图感知，机器人在人机共融的环境中具有社交意识的导航
		- 近年来，机器人在人机交互社交环境中的部署数量显著增加。为了确保人与机器人之间的和谐共融，机器人能够在人类环境中进行导航并理解社会规范和个人边界是非常关键的。在这方面，我们提出了一种基于强化学习的社交感知机器人导航框架。该框架通过考虑行人的情绪，采用基于情感的邻近奖励函数。此外，我们我们还引入了一种称为个人空间地图的新型信息融合形式，该方法结合了预测的人类意图和基于情感的个人空间，作为强化学习策略的观测值。实验结果表明，我们的框架使得机器人能够在人群中进行导航，而不会引起情绪状态不同的行人的不适，同时确保高效的路径规划。
		- 近年来，机器人在人机交互社交环境中的部署数量迅速增加。为了实现人与机器人的和谐共融，重要的是让机器人能够在人类环境中导航并遵循社会规范和个人边界。为此，我们提出了一种基于强化学习的社交感知机器人导航框架。该框架考虑了行人的情绪，采用了基于情感的邻近奖励函数。此外，我们还引入了一种名为个人空间地图的新型信息融合形式，该方法结合了预测的人类意图和基于情感的个人空间，作为强化学习策略的观测值。实验结果表明，我们的框架使得机器人能够在人群中进行导航，而不会引起情绪状态不同的行人的不适，同时还能确保高效的路径规划
		- 近年来，机器人在人机交互社交环境中得到了广泛应用。为了保证人与机器人之间的和谐共处，机器人的导航能力和对社会规范以及个人边界的理解就显得尤为重要。为此，我们提出了一种基于强化学习的社交感知机器人导航框架。这个框架通过考虑行人的情绪，采用基于情感的邻近奖励函数来引导机器
		- 近年来，机器人在人机交互社交环境中的应用数量显著增加。为了实现人与机器人之间的和谐共存，机器人必须具备导航能力，并能理解社会规范和个人边界。为了解决这一问题，我们提出了一种基于强化学习的社交感知机器人导航框架。该框架考虑了行人的情绪，并使用基于情感的邻近奖励函数来指导机器人的行为。我们还引入了一种称为个人空间地图的新型信息融合方式，将预测的人类意图和基于情感的个人空间结合起来，作为强化学习策略的观察值。实验结果表明，我们的框架使机器人能够在人群中导航，而不会引起情绪状态不同的行人的不适，同时确保了高效的路径规划。
	- 应用场景
		- 近年来，机器人在以人为中心的环境中的部署越来越常见。在公共场所和社交活动中，机器人的存在越来越引人注目，从引导参观者的服务机器人到与会议参与者进行交流的互动机器人伴侣。在这样广泛的应用中，机器人以深入理解人类社交规范和个人边界的方式在人类环境中导航已成为必要，这有助于人类和机器人之间的和谐共处。事实上，实现机器人和人类之间无缝和谐互动的关键在于机器人在导航过程中展现出社交意识的行为能力。一个具有社交意识的机器人应该能够理解和适当地回应人类的线索、表情和意图，从而在人类中树立信任和自信。然而，挑战在于人类社交动态的内在复杂性，涵盖了众多未明示的规则、文化细微差别和个体偏好。
		  反过来，社交意识导航成为机器人在人机交互环境中部署的关键挑战。特别是，社交意识导航是一个流行的新兴研究课题，融合了机器人感知、人机交互和路径规划。事实上，大部分传统的路径规划方法对于人口密集环境中的导航挑战不足或无法胜任，因为它们忽视了环境中存在的智能实体，比如人类。相比之下，一个具有社交意识的机器人应该通过观察环境并有目的地行为，对周围环境进行认知，以改善人类的舒适和安全感，将人们不仅仅视为障碍物，而是社会主体。
		- 机器人在以人为中心的环境中的部署越来越普遍。它们在公共场所和社交活动中扮演重要角色，例如引导参观者的服务机器人和与会议参与者互动的伴侣机器人。在这样广泛的应用中，机器人需要深入理解人类社交规范和个人边界，以实现与人类和谐共处。这要求机器人具备一定的社交意识来导航自己在人类环境中的行为。一个具有社交意识的机器人能够理解和适当地回应人类的线索、表情和意图，从而建立起人与机器人之间的信任和自信。然而，挑战在于人类社交动态的复杂性，其中包含了许多未明示的规则、文化差异和个体偏好。
		  反过来，社交意识导航成为机器人在人机交互环境中部署的关键挑战。特别是，社交意识导航是一个新兴的研究课题，融合了机器人感知、人机交互和路径规划等领域。许多传统的路径规划方法无法有效处理人口密集环境中的导航挑战，因为它们忽视了智能实体（如人类）的存在。相比之下，一个具有社交意识的机器人应该通过观察环境和有目的地行动，以改善人类的舒适和安全感，将人类视为社会主体而非简单的障碍物。这需要机器人能够认知周围环境并作出相应的行动。这个领域的研究正不断发展，以实现机器人和人类之间更加和谐和自然的互动。
		- 近年来，机器人在以人为中心的环境中的部署变得越来越普遍。无论是在公共场所还是社交活动中，我们都能越来越常见地看到机器人的身影。它们可以是引导参观者的服务机器人，也可以是与会议参与者互动交流的机器人伴侣。在这样广泛的应用中，机器人能够深入理解人类社交规范和个人边界，并在人类环境中自如地导航，这对于人与机器人之间的和谐共处至关重要。实际上，实现机器人与人类之间无缝和谐互动的关键在于机器人展现出社交意识的行为能力。一个具备社交意识的机器人应该能够理解和适当地回应人类的线索、表情和意图，从而在人类中树立信任和自信。然而，挑战在于人类社交动态的内在复杂性，其中包含了众多未明确规定的规则、文化上的微妙差异和个体偏好。
		  反过来，社交意识导航成为机器人在人机交互环境中部署的关键挑战。特别是，社交意识导航是一个流行的新兴研究课题，它融合了机器人感知、人机交互和路径规划等领域。事实上，传统的路径规划方法在人口密集环境中面临着很大的挑战，因为它们忽视了环境中存在的智能实体，如人类。相比之下，具备社交意识的机器人应该能够通过观察环境并有目的地行动，对周围环境进行认知，以改善人类的舒适度和安全感，将人们视为社会的一部分，而不仅仅是障碍物。
	- result
		- 研究结果表明，将人的情感考虑进入在人口密集环境中的路径规划可以显著提高规划策略的效率，特别是在密闭环境下有大量人群的情况下。此外，将人的情感纳入到人群导航中还可以使机器人在导航过程中更加符合社交习惯，从而让人们感到更加舒适。
		- 研究结果显示，在人口密集的环境中，将人的情感纳入路径规划可以显著提高规划策略的效率，尤其是在密闭环境下有大量人群的情况下。此外，将人的情感纳入到人群导航中还可以使机器人更好地符合社交习惯，从而让人们在导航过程中感到更加舒适。
		- 研究结果表明，将人的情感因素考虑纳入到路径规划的算法中，可以明显提高策略规划的效率，特别是在封闭环境中有大量人群的情况下。此外，将人的情感因素融入到导航策略中，还可以促使机器人在导航过程中更符合社交习惯，从而进一步提升人们的舒适感。
		- 研究结果显示，将人的情感考虑纳入到人口密集环境中的路径规划中，可以明显提高规划策略的效率，特别是在封闭环境中有大量人群的情况下。此外，将人的情感因素融入人群导航中，还可以使机器人在导航过程中更符合社交习惯，以提供更舒适的体验。
- keyword:
	- socially aware navigation
	- social navigation
	- co-exist
	- socially acceptable behavior
	- social comfort
	- Proxemics: theory of social distance
	- social agreeable cruising
- abstract
	- keywords (4 - 7)
		- socially-aware navigation
		- human-aware navigation
		- human-robot coexisting environment
		- social human-robot interaction
		- crowd navigation
		- reinforcement learning
		- social robotics
	- what are the limitations of current research?
	- what is the contributions of this work to tackle the aforementioned limitations
		- new architecture / framework / concept
		- introduces / merges / fuses psychology concept (emotional promexic) to navigation policy (machine learning)
			- emotional adaptive promexic / comfort space
	- combines aforementioned contributions into **full name** (EmoPlanner)
		- in other way, aforementioned contributions had defined EmoPlanner
	- source {{renderer :wordcount_}}
		- Definition:
			- The deployment of robots in human-centric environments has increased significantly in recent years. It is crucial for robots to navigate human environments while understanding social norms and personal boundaries to ensure harmonious coexistence between humans and robots.
			- A socially aware robot should be capable of interpreting and responding appropriately to human cues, expressions, and intentions, thereby engendering trust and confidence among humans.
		- current limitations / research gap (objective):
			- However, existing path planning methods are insufficient or unable to cope with navigation challenges in human-populated environments, since they perceive people as obstacles but not as social agents.
			- previous works
			- prior studies
			- Existing literature
			- the challenges lie in the inherent complexity of human social dynamics, encompassing a myriad of unspoken rules, cultural nuances, and individual preferences
			- However, existing path planning methods are insufficient or unable to cope with navigation challenges in human-populated environments, since they overlook the existence of intelligent entities like people in the environment.
			- people really obey such exact geometrical rules, because it is difficult to manually model human behavior.
			- highly sophisticated human behavior
			- a socially-aware robot should have a cognitive understanding of its surroundings by observing the environment and behaving with the purpose of improving human comfort and safety, by perceiving people **not just as obstacles but as social agents**
			- similar proxemic areas that are present in interpersonal interaction may also be utilized in human-robot interaction circumstances, but these prohibited areas enforced by proxemics for social robot navigation should inconsistent
			  id:: 6556ba3c-2d04-4571-bb11-b794d439e057
			- the proxemic areas supposed to fluctuate depending on various factors, but not consistent just for safety purpose
			- there is a high possibility that the robot would “**freeze**”, and be unable to travel despite there being available areas for movement
			- However, the challenges lie in the inherent complexity of human social dynamics, encompassing a myriad of unspoken rules, cultural nuances, and individual preferences.
		- our methods:
			- adaptive proxemics
			- personal space map
			- accounts for pedestrian emotions by designing the reward function with emotion-based proxemic restrictions
			- approximate the personal spaces of people in the future timeframe, so that the robot is able to avoid interception of the path to be taken by the people
			- personal space map, which combines predicted human intention and emotion-based personal space
			- robust navigation behavior: reinforcement learning
			- our approach utilizes a social interaction-based human trajectory predictor to estimate the intentions of individuals and forecast their future personal spaces. This enables the robot to avoid intersecting with the paths intended by people. Additionally, we introduce the personal space map, which combines predicted human intentions and emotion-based personal space, as a novel representation. Finally, we address the challenge of socially-aware robot navigation using a reinforcement learning-based method. In this approach, the personal space map serves as the observation for the policy, with emotion-based proxemic restrictions incorporated into the reward function.
		- This paper proposes a reinforcement learning-based socially-aware robot navigation framework that considers pedestrian emotions through an emotion-based proxemic reward function. Besides, this paper introduces a novel representation called the personal space map, which combines predicted human intention and emotion-based personal space, and serves as the observation for the reinforcement learning policy.
		- Our framework was subjected to case studies involving realistic crowd navigation scenarios, and the results indicate that it enables robots to navigate through crowds without causing discomfort to pedestrians who exhibit stochastic behaviors and emotional states,  while also ensuring efficient path planning.
	- {{renderer :wordcount_, 250}}
		- The deployment of robots in human-centric environments has increased significantly in recent years. It is crucial for robots to navigate human environments while understanding social norms and personal boundaries to ensure harmonious coexistence between humans and robots. A socially aware robot should be capable of interpreting and responding appropriately to human cues, expressions, and intentions, thereby engendering trust and confidence among humans. However, prior studies are insufficient or unable to cope with navigation challenges in human-populated environments, since they perceive people as obstacles but not as social agents. Recent studies utilized proxemic areas that are present in interpersonal interaction for human-robot interaction circumstances, but they enforced consistent proxemic areas for social robot navigation, which caused the navigation policy could not fully capture the highly sophisticated human's behavior and preference. Therefore, we introduce an psychologically-based adaptive proxemic area that fluctuate based on the human's emotional state. Next, we integrated this feature to a reinforcement learning-based social navigation framework, so that our navigation framework is robust to the erratic human's affection. Besides, our navigation framework also includes human's intention prediction to approximate the future proxemic area, to avoid interception of the path to be taken by the people. We name our framework as Emotion and Intention Aware Path Planner (EmoiPlanner). Our framework was subjected to case studies involving realistic crowd navigation scenarios, and the results indicate that it enables robots to navigate through crowds without causing discomfort to pedestrians who exhibit stochastic behaviors and emotional states,  while also ensuring efficient path planning.
	- {{renderer :wordcount_}}
		- The deployment of robots in human-centric environments has significantly increased in recent years. It is crucial for robots to navigate human environments while understanding social norms and personal boundaries to ensure a harmonious coexistence between humans and robots. A socially aware robot should be capable of interpreting and responding appropriately to human cues, expressions, and intentions, thereby fostering trust and confidence among humans. However, prior studies have been insufficient or unable to address the navigation challenges in human-populated environments, as they perceive people as obstacles rather than social agents. Recent studies have utilized proxemic areas that are present in interpersonal interactions for human-robot interaction scenarios, but they have enforced consistent proxemic areas for social robot navigation. This approach fails to fully capture the highly sophisticated behavior and preferences of humans. Therefore, we propose a psychologically-based adaptive proxemic area that fluctuates based on the human's emotional state. Furthermore, we integrate this feature into a reinforcement learning-based social navigation framework, making our navigation framework robust to the unpredictable affections of humans. Additionally, our navigation framework includes human intention prediction to approximate the future proxemic area, thereby avoiding interference with the path to be taken by individuals. We have named our framework the Emotion and Intention Aware Path Planner (EmoiPlanner). Our framework has been subjected to case studies involving realistic crowd navigation scenarios, and the results indicate that it enables robots to navigate through crowds without causing discomfort to pedestrians who exhibit stochastic behaviors and emotional states, while also ensuring efficient path planning.
- Future work
	- As future research directions we intend to consider others factors besides humans' emotions, such as, social grouping, gazes, gaits and hand gestures of humans. Future improvements of the policy should account for the aforementioned factors to fully capture real human behavior.
- Introduction
  collapsed:: true
	- In recent years, the integration of robots into human-centric environments has become increasingly common. In public spaces and social events, the presence of robots is increasingly noticeable, ranging from service robots guiding visitors in museums to interactive robotic companions engaging in conversation with attendees at conferences. With such extensive involvement, it has become imperative for robots to navigate within human environments with a profound understanding of human social norms and personal boundaries, which facilitates harmonious coexistence between humans and robots. Indeed, the crux of achieving seamless and harmonious interaction between robots and humans lies in the ability of robots to exhibit socially-aware behaviors during navigation. A socially aware robot should be capable of interpreting and responding appropriately to human cues, expressions, and intentions, thereby engendering trust and confidence among humans. However, the challenges lie in the inherent complexity of human social dynamics, encompassing a myriad of unspoken rules, cultural nuances, and individual preferences.
	- Consequently, socially-aware navigation becomes a vital issue for robots deployed in human-robot interactive social environments. In particular, socially aware navigation is an active new research field combining robot perception, human-robot interaction and motion planning. In fact, most of the classic path planning algorithms become inefficient or inadequate to deal with navigation problems in human inhabited dynamic environments, as they disregard the presence of intelligent agents such as humans in the environment. A socially aware mobile robot requires situational awareness of its surroundings by perceiving the environment and acting with the aim of increasing human safety and comfort. That is, the robot will consider the human not only as an obstacle but as a social entity. We aim to have the robot adhere to the above definitions and other such cultural and social norms, to achieve human acceptance and trust.
	- contribution\
		- we propose a reinforcement learning-based socially-aware robot navigation framework that accounts for pedestrian emotions by designing the reward function with emotion-based proxemic restrictions.
		- we introduce personal space map as a novel combination of predicted intentions of other agents and emotion-based personal space, which serves as the observation of the RL policy. Our method is compatible with any trajectory predictor.
		- The result demonstrates that our framework allows robot to navigate through a crowd without causing discomfort to the pedestrians with variable emotional state, while ensuring the efficiency of path planning.
		-
		-
- contribution (source)
  collapsed:: true
	- we adopts the agent-level information of the environment such as the positions and comfort spaces of pedestrians into a personal space map (a grayscale image), and leverages CNN to interpret the map.
	- we leverages reinforcement learning-based approach to tackle this problem, and incorporates the social norms and social restrictions during training of the policy.  In particular, personal space map is introduced as the observation of RL policy, where the map contains information about the comfort regions of pedestrians, and the reward function of RL training is designed with incorporation of emotion-based proxemic restrictions.
	- In this work, we leverages the human trajectory predictor to estimate the intentions of people, and thus approximate the personal spaces of people in the future timeframe, so that the robot is able to avoid interception of the path to be taken by the people.
	- A human-aware navigation system based on long-term movement prediction, human comfort constraints, and path planning on a time-dependent cost-map.
	- We present a new navigation scheme using Proxemic Fusion that accounts for pedestrian emotions.
	- introducing socially aware collision avoidance with deep reinforcement learning (SA-CADRL) for explaining/inducing socially aware behaviors in a RL framework
		- generalizing to multiagent (n > 2) scenarios through developing a symmetrical neural network structure
	- we address this problem with a relational graph learning approach for model-based RL, which predicts future human motions and plans for crowd navigation simultaneously.
	- We propose a graph-based policy network that uses attention mechanism to effectively capture the spatial and temporal interactions among heterogeneous agents.
	- We propose a novel method to incorporate the predicted intentions of other agents into a model-free RL framework. Our method is compatible with any trajectory predictor.
	- We also present a novel navigation planning algorithm based on deep reinforcement learning that takes into consideration the environment, pedestrian intent, and the robot's reactionary impact on pedestrian behavior.
	- we introduce an adaptive spatial density function to represent the proximal constraints for pedestrians that captures pedestrians' unique personal comfort space in terms of pose, intent, and emotion.
	- We create a novel combination of data representations for the input to our neural network-based control policy, using a short history of pooled lidar data, the current kinematics of nearby pedestrians, and a sub-goal point. We design these representations to be robust to localization errors by putting all data into the robot's local coordinate frame and to improve generalizability to new environments by handcrafting higher-level representations from the raw sensor data.
	- the inclusion of the space affordances concept in thissocial navigation system. In particular, this paper significantly ex-tends the work initially presented in [43], including a thoroughassessment of the adaptive spatial density function; the applica-tion and evaluation of the affordances space for interactive scenar-ios; the application and evaluation of the social navigation stack toboth, real and simulated scenarios, considering a wider set of met-rics; and a comparison of the proposed social navigation approachwith respect to non human aware navigation system.
	- **The experiments demonstrate that our method outperforms previous works in terms of navigation performance and social awareness.** (efficiency and social comfort)
	- The result indicates that, the efficient of path planned by the policy could be significantly improved by incorporating the emotions of humans into crowd navigation, especially when there are large amount of humans in a confined environment. Besides that, incorporation of the emotions of humans into the crowd navigation also allows the robot managed to have a more socially agreeable cruising, where the humans felt more comfortable while the robot is navigating around them.
	- We validate the navigation performance in multiple simulated 3D environments and demonstrate that the proposed control policy achieves a better trade-off between collision avoidance and speed, and generalizes better to different crowd sizes and new unseen environments than state-of-art approaches, including a model-based controller [4], a supervised learning-based approach [5], and two DRL-based approaches [6].
	-
- The remainder of this paper is organized as follows: inSection 2 we present a review of related work. An overview of theproposed navigation system is described in Section 3. The adaptivespatial density function and space affordances for social mappingare presented in detail in Section 4 and Section 5, respectively.
- Introduction (source)
  collapsed:: true
	- Usually, robots working in human environments have used navigation algorithms where all obstacles are considered of similar relevance, including people. To avoid discomforting humans, social robots must consider them special entities, evaluating the people'level of comfort with respect to the route of the robot.Usually, robots working in human environments have used navigation algorithms where all obstacles are considered of similar relevance, including people. To avoid discomforting humans, social robots must consider them special entities, evaluating the people'level of comfort with respect to the route of the robot.
	- With the recent developments in robotics, mobile service robots start taking place in our lives, accompany us in human interactive environments, such as airports, hospitals, schools, and offices. For a safer interaction, and to be accepted as a social being, mobile service robots must be aware of the presence of the human, social rules and cues, for example, differentiate between humans (human-aware) and the other ordinary objects in the environment, respect other people's personal spaces, perceive social relations, and navigate by anticipating other people's reactions as much as possible.
	- Consequently, socially aware navigation becomes a vital issue for service robots deployed in human-robot interactive social environments. Socially aware navigation is an active new research field combining perception, human-robot interaction and motion planning with a common goal.
	- Mobile service robots and assistive robots operating and navigating in human inhabited environments require new approaches involving social skills. Some of these robots might operate in dynamic environments, rather than performing specific tasks in controlled static environments. Most of the state-of-the-art path planning algorithms become inefficient or inadequate to deal with navigation problems in human inhabited dynamic environments, as they disregard the presence of intelligent agents such as humans in the environment. A socially aware mobile robot requires situational awareness of its surroundings. It perceives the environment and acts with the aim of increasing human safety and comfort. That is, the robot will consider the human not only as an obstacle but as a social entity. We aim to have the robot adhere to the above definitions and other such cultural and social norms, to achieve human acceptance and trust.
	- In recent years, the integration of robots into human-centric environments has become increasingly common. In public spaces and social events, the presence of robots is increasingly noticeable, ranging from service robots guiding visitors in museums to interactive robotic companions engaging in conversation with attendees at conferences. With such extensive involvement, it has become imperative for robots to navigate within human environments with a profound understanding of human social norms and personal boundaries, which facilitates harmonious coexistence between humans and robots. Indeed, the crux of achieving seamless and harmonious interaction between robots and humans lies in the ability of robots to exhibit socially-aware behaviors during navigation. A socially aware robot should be capable of interpreting and responding appropriately to human cues, expressions, and intentions, thereby engendering trust and confidence among humans. However, the challenges lie in the inherent complexity of human social dynamics, encompassing a myriad of unspoken rules, cultural nuances, and individual preferences.
- Related work
  id:: 64fa1b3e-5eb2-4f14-9185-2b6cf536649f
	- # Crowd Navigation
		- There is an abundance of research that concentrate on crowd navigation challenges, with solutions ranging from classic model-based methods to supervised learning-based methods to reinforcement learning-based methods.
		- ## traditional model-based approaches
			- A typical model-based crowd navigation approach is the Social Force (SF) Model [19], which has been successfully applied and extended in different environments [7], [20], [21]. Reciprocal velocity obstacles (RVO), which consider communications with other agents, were proposed in multiagent navigation scenarios [2]. More recently, ORCA was proposed in [3]. It enables multiple robots to avoid collisions when navigating in a cluttered workspace.
			  
			  Although SF, RVO and ORCA take mutual interactions among agents into account, the **hyperparameters are sensitive to crowd behaviors and thus need to be tuned carefully to ensure good performance**, thus making them **difficult to implement and generalize** to new scenarios. [17]. They may also lead to **unnatural robot behaviors**, since their designs do not **fully capture real human behavior**. Also, it has been observed that model-based methods can lead to **oscillatory paths** [2], [14]. In addition, model-based approaches are **prone to failures if the assumptions such as the reciprocal rule no longer hold**, since  it is **unclear whether the humans do follow such precise geometric rules** [10], [18].
		- ## supervised learning-based approaches
			- supervised learning-based approaches aim to to develop a policy that emulates human behaviors by transferring the human behavior model to the path planner of the robot via machine learning algorithms. In particular, Inverse Reinforcement Learning (IRL) [15] has been applied to learn a cost function from teleoperation demonstrated by human [16], and a probability distribution over the set of joint trajectories with nearby pedestrians [2], [17]. Compared with model-based approaches, learning-based methods have been shown to **produce paths that more closely resemble human behaviors**. However, since **human behaviors are inherently stochastic, the feature statistics calculated on pedestrians' paths can vary significantly from person to person**, and even run to run for the same scenario [2], [16]. This raises **concerns over whether such feature-matching methods are generalizable to different environments** [13]. In short, supervised learning-based approaches are **purely data-driven and easy to use**, but require **laboriously collecting a representative set of expert demonstrations** to train a generalized network [5], [20]–[24].
		- ## reinforcement learning-based approaches
			- Reinforcement learning algorithms learn policies while the robot interacts with the environment through **trial-and-error**. For robot navigation, recent work has used reinforcement learning methods to learn policies from **raw sensor inputs** [26] or **agent-level representations of the environment** [9], [10]. In particular, **an agent level representation can provide a richer high-level representation of pedestrian intent that is difficult to extract from raw sensor information**. However, agent-level representations of the environment possessed **one challenge which is the vary of crowd size**. Everett et al. [10] converted the state of a variable sized crowd to a fixed-length vector using an LSTM module that processed each pedestrian's state in descending order of their distance from the robot. However, the assignment of the importance according to distance is not always reasonable. For example, a pedestrian closely following a robot may be less important than a farther pedestrian in front of it. A recent work [9] adopted a self-attention module to assign different relative importances to different parts of the crowd. Moreover, [15] encoded both the location and velocity information of detected pedestrians into a pedestrian map (a RGB image), and leveraged Convolutional Neural Network (CNN) to extract features from the map.
			- In this work, the agent-level representations of the environment are adopted into a personal space map, and Convolutional Neural Network (CNN) is leveraged to deduce the map.
			- In our work, we infer the relative importance of neighboring humans to the robot by learning attention weights from gaze data collected from humans performing a crowd navigation task.
			- Reinforcement learning-based approaches are **experience-driven and similar to human learning**, but **require carefully designing a reward function** [6], [26]–[41]. Although each type of approach has its own advantages and disadvantages, **we choose the reinforcement learning-based approach because it is difficult to manually design general rules within model-based approaches or collect sufficient effective representative training data in uncontrolled and human-filled environments for supervised learning-based approaches.**
		- ## Preference learning-based approaches
			- Active preference or feedback learning [16], [17], which depends on human feedback rather than demonstrations, thus allowing corrective and flexible instructions to direct the learning process, may act as a great alternative for overcoming the above-described issues. Such interactive reinforcement learning may adapt robot actions to human preference spontaneously, without reward design and exploitation. In addition, it has no need for and hence is not restricted by expensive human demonstrations. For instance, [11][12] embed human comfort and anticipation into a reward model and then into robot policy, leading to more desired and intuitive robot behaviour. In contrast with present reinforcement learning-based approaches, [11][12] compiles the reward model from human preferences instead of handcrafting it, addresses social compliance more naturally and thoroughly, and avoids the reward exploitation issue that leads to inappropriate robot actions. Also, unlike supervised learning-based approaches, [11][12] presents expert intelligence without being hampered by expensive, noisy, and rare human demonstrations, nor from substantial feature engineering.
	- # Incorporation of Humans' Emotions / adaptive personal space / Social Navigation
		- Humans navigating among crowds follow social norms relating to the speed of movement or personal space. In particular, **we tend to observe the emotions displayed by others and adjust our paths in response**.  Correspondingly, recent studies have been focused more on **robots' sociability**. The main idea is to create socially acceptable behaviors for robots during their navigation, what has been introduced as social mapping [3]. This **social mapping deals with the problem of human-aware robot navigation and considers factors like human comfort,sociability, safety and naturalness** [18]. Under this prism, different works have shown that the same proxemic zones that exist in human-human interaction can also be applied to human-robot interaction scenarios [23,24,45]. Thus, a broad survey and discussion regarding the **social concepts of proxemics theory applied in the context of human-aware autonomous navigation** was presented in [33,34]. Most of these works define **areas where robot navigation is forbidden**, that is,when social robots plan to navigate, they must be aware of the permitted and forbidden actions in social spaces [33].
		- However, these forbidden regions imposed by proxemics for robot navigation are not permanent,as several authors have pointed out, and can vary accordingly to different aspects. In particular, [22] use a **perceptual model that takes into account the relative pose between human and robot, the human gestures and the speech volume for building the social space**. In addition, [10] proposed **Dynamic Social Zone** to describe social space by considering human states such as position, orientation, motion and hand poses. Furthermore, [12,13] produce a **dynamic human-aware proxemic costmap** that alters by adding gaussian costs around the detected dynamic or static person**, so that the robot navigate among humans in a collision free manner by respecting their personal or social zones. Using this representation, [15] incorporated **emotion-based proxemic constraints** into the social navigation framework.
		- Most of these socially-aware navigation algorithms are based on using a classic navigation algorithm, and therefore **adding social conventions and/or social constraints**. Consequently, if there are one or more pedestrians around the robot that **block the possible paths of the robot, the robot might ''freeze", and can not move although there is available space for action**.
		-
		- use DRL, but design specific reward function
	- # Trajectory prediction-based methods / Human Intention
		- **Works like [21] demonstrates that navigation algorithms based on proxemic are not always the best choice, and there exist more attributes that provide in robot socially agreeable cruising. There exist other solutions for social navigation which use the detection of human intentions in order to model the social navigation**. In social robotics, an **accurate prediction of pedestrian trajectories plays a significant role in robot decisions in terms of reactive response, navigation planning**, etc. For simplicity and ease of computation for navigational robots, the problem of pedestrian intention prediction is largely modeled as a trajectory prediction problem.
		- Recently, researchers have studied how interactive factors affect agents' trajectory plans, like social interaction [1,15,36,60] and scene interaction [31,56]. The modeling of agents' trajectories also matters how the trajectory prediction networks perform. Alahi et al. [1] treat this task as a sequence generation problem, and they employ LSTMs to model and predict pedestrians' positions in the next time step recurrently. A series of works have also introduced Graph Neural Networks (GNNs), e.g. Graph Attention Networks (GATs) [15,22,27] and GCNs [4,36], to handle interactive factors when forecasting. Moreover, the attention mechanism has been employed [51,55,60] to focus on the most valuable interactive targets to give reasonable predictions. With the success of Transformers [50] in sequence processing such as natural language processing, researchers [13,58] have employed Transformers to obtain better feature representations. Some researchers address agents' uncertainty and randomness by introducing generative models. Generative Adversarial Networks (GANs) are employed in [14,43,22] to generate multiple stochastic trajectories to suit agents' various future choices. Some works like [17,45] use the Conditional Variation AutoEncoder (CVAE) to achieve the similar goal.
		- Utilizing the recent advancements in pedestrian trajectory prediction [19]–[22], one line of work **uses the predicted human states to compute the transition probabilities of Markov Decision Process (MDP) and then plans optimal robot actions with search trees** [11], [23], [24]. However, the computation cost of tree search grows exponentially with the size of robot action space. Another line of work **uses the one-step predictions as observations of model-free RL policies** [12], [25]. Although the action space can be large and continuous, one-step predictions only capture the instantaneous velocities instead of intentions of pedestrians. On the other hand, [60] **makes predictions for several timesteps to capture the long-term intents of pedestrians** and modify the reward function based on predictions so that the robot is intention-aware.
		- Leveraging the human trajectory predictor mentioned above, one line of research utilizes the estimated pedestrian trajectories to calculate the transition probabilities of the Markov Decision Process (MDP) and then determines optimum robot movements with search trees \cite{navigation_pred_search_tree1, navigation_pred_search_tree2, navigation_pred_search_tree3}. However, the rise in size of the robot's action space will exponentially increase the computational cost of tree search. Thus, another line of research utilizes the one-step forecasts as observations of model-free RL policies \cite{RL_one_step_pred1, RL_one_step_pred2}. Despite the action space of the robot could be continuous, one-step forecasts only account for the immediate velocities rather than the intents of individuals. On the other hand, \cite{RL_intention} estimates forecasts for multiple timesteps to approximate the long-term intents of people and uses long-term trajectory prediction as inputs to model-free RL policies, and the reward function is designed based on the forecasts so that the policy is aware of humans' intents. In this work, we leverages the human trajectory predictor to estimate the personal spaces of pedestrians in future timeframe.
	- # Perception and recognition of humans' psychology state
		- Face and speech data have been widely used to perceive human emotions. Prior methods that use faces as input commonly track action units on the face such as points on the eyebrow, cheeks and lips [16], or track eye movements [39] and facial expressions [33]. On the other hand, speech-based emotion perception methods use either spectral features or prosodic features like loudness of voice, difference in tones and changes in pitch [24]. With the rising popularity of deep learning, there is considerable work on developing learned features for emotion detection from large-scale databases of faces [51, 53] and speech signals [12].
		- Besides that, there also exists a substantial amount of research that focuses on identifying the emotions of humans based on body posture, movement, and other non-verbal cues. [30], [31] classify emotions into four classes based on affective features obtained from 3D skeletal poses extracted from human gait cycles. With the aid of machine learning, [1][2] leverage graph neural network to utilize a person's gait from a walking video to predict their emotion.
		- Recent methods have also looked at the cross modality of combined face and speech data to perform emotion recognition [1]. Also, [8] uses multiple modalities such as facial cues, human pose and scene understanding. Moreover, [33] classifies emotions based on facial expressions along with a pedestrian trajectory obtained from overhead cameras.
	- # Modelling of Human-Robot Interaction in crowd navigation
		- Works like [21] demonstrates that navigation algorithms based on reactive response are not always the best choice, and there exist more attributes that provide in robot socially agreeable cruising. There exist other solutions for social navigation which use the interpretation of human intentions in order to model the human-robot Interaction in social navigation.
		- For simplicity and ease of computation for navigational robots, the problem of pedestrian intention prediction is mostly modeled as a trajectory prediction problem. Recently, researchers have studied how interactive factors affect agents' trajectory plans, like social interaction [1,15,36,60] and scene interaction [31,56]. The modeling of agents' trajectories also matters how the trajectory prediction networks perform. Alahi et al. [1] treat this task as a sequence generation problem, and they employ LSTMs to model and predict pedestrians' positions in the next time step recurrently. A series of works have also introduced Graph Neural Networks (GNNs), e.g. Graph Attention Networks (GATs) [15,22,27] and GCNs [4,36], to handle interactive factors when forecasting. Moreover, the attention mechanism has been employed [51,55,60] to focus on the most valuable interactive targets to give reasonable predictions. With the success of Transformers [50] in sequence processing such as natural language processing, researchers [13,58] have employed Transformers to obtain better feature representations. Some researchers address agents' uncertainty and randomness by introducing generative models. Generative Adversarial Networks (GANs) are employed in [14,43,22] to generate multiple stochastic trajectories to suit agents' various future choices. Some works like [17,45] use the Conditional Variation AutoEncoder (CVAE) to achieve the similar goal.
		- The aforementioned approaches generally require an overhead camera to track the pose of every pedestrian around the robot. However, the images captured by the overhead camera are usually inaccessible to the robot during crowd navigation. As a result, the aforementioned methods may not perform well due to the limited sensing capabilities of the robot's camera, such as a limited sensor field of view and obstructing human agents [5]. In order to address the issue of occlusion, [20][21] introduce a novel approach that leverages skeletal joint kinematics as input for human trajectory prediction. These models rely solely on the trajectory and kinematics of joints to interpret the intent of humans. Furthermore, [6] utilizes transformers to predict the full-body pedestrian intent or behavior based on historical gait sequences obtained from the robot's camera in an egocentric view.
		- Utilizing the recent advancements in pedestrian trajectory prediction [19]–[22], one line of work **uses the predicted human states to compute the transition probabilities of Markov Decision Process (MDP) and then plans optimal robot actions with search trees** [11], [23], [24]. However, the computation cost of tree search grows exponentially with the size of robot action space. Another line of work **uses the one-step predictions as observations of model-free RL policies** [12], [25]. Although the action space can be large and continuous, one-step predictions only capture the instantaneous velocities instead of intentions of pedestrians. On the other hand, [60] **makes predictions for several timesteps to capture the long-term intents of pedestrians** and modify the reward function based on predictions so that the robot is intention-aware.
		- Leveraging the human trajectory predictor mentioned above, one line of research utilizes the estimated pedestrian trajectories to calculate the transition probabilities of the Markov Decision Process (MDP) and then determines optimum robot movements with search trees \cite{navigation_pred_search_tree1, navigation_pred_search_tree2, navigation_pred_search_tree3}. However, the rise in size of the robot's action space will exponentially increase the computational cost of tree search. Thus, another line of research utilizes the one-step forecasts as observations of model-free RL policies \cite{RL_one_step_pred1, RL_one_step_pred2}. Despite the action space of the robot could be continuous, one-step forecasts only account for the immediate velocities rather than the intents of individuals. On the other hand, \cite{RL_intention} estimates forecasts for multiple timesteps to approximate the long-term intents of people and uses long-term trajectory prediction as inputs to model-free RL policies, and the reward function is designed based on the forecasts so that the policy is aware of humans' intents. In this work, we leverages the human trajectory predictor to estimate the personal spaces of pedestrians in future timeframe.
- Source
	- Why?
		- coexist
		- socially acceptable behaviour
		- avoid discomfort
		- human-robot society
	- treats humans as dynamic obstacle (Model-based Approaches)
	  collapsed:: true
		- social force
		- VO
		- RVO
		- ORCA
		- APF
		- Typical model-based approaches **compute efficient paths** and the **parameters are easily interpretable**, but require **manually adjusting model parameters for different scenarios** [4], [9]–[19].
		- A common approach treats pedestrians as dynamic obstacles with simple kinematics, and employs specific reactive rules for avoiding collision [3]–[6]. Since these methods do not capture human behaviors, they sometimes generate unsafe/unnatural movements, particularly when the robot operates near human walking speed [2]. To address this issue, more sophisticated motion models have been proposed, which would reason about the nearby pedestrians' hidden intents to generate a set of **predicted paths** [7], [8]. Subsequently, classical path planning algorithms would be employed to generate a collision-free path for the robot. Yet, separating the navigation problem into disjoint prediction and planning steps can lead to the **freezing robot problem**, in which the robot fails to find any feasible action because the predicted paths could mark a large portion of the space untraversable [9]. A key to resolving this problem is to account for cooperation, that is, to model/anticipate the impact of the robot's motion on the nearby pedestrians.
		- A typical **model-based approach** is the ROS [8] navigation stack, which uses costmaps to store obstacle information and uses the dynamic window approach (DWA) planner [4] to do local planning. Based on the ROS navigation stack, [9] recently add human safety and visibility costmaps into both global and local planners to handle human-aware navigation problems. Another class of model-based approaches are velocity obstacle-based algorithms [10]–[12], which map the dynamic environment into the robot velocity space and generate safe control velocities from these velocity constraints. Similarly, Arul et al. [13] combine reciprocal velocity obstacles with buffered Voronoi cells to solve multi-agent navigation problems. A third class of model-based approaches uses model predictive control [14], [15], which can integrate collision avoidance and obstacle dynamics into robot constraints. Other model-based approaches attempt to directly model how humans and robots interact, using social forces [16], [17], Gaussian mixture models (GMM) [18], or a combination of potential functions and limit cycles [19]. All those model-based methods require knowledge of pedestrian kinematics, utilize multi-stage procedures to process sensor data, and often require practitioners to carefully **hand-tune** model parameters, making them **difficult to implement and generalize** to new scenarios.
		- Robot navigation in dynamic crowds has been explored for decades [1], [14]–[16]. Optimal reciprocal collision avoidance (ORCA) models other agents as velocity obstacles and assumes that agents avoid each other under the reciprocal rule [2], [4]. Social Force (SF) models the interactions between the robot and other agents using attractive and repulsive forces [5]. Although ORCA and SF account for mutual interactions among agents, the **hyperparameters are sensitive to crowd behaviors and thus need to be tuned carefully to ensure good performance** [17]. In addition, both methods are **prone to failures if the assumptions such as the reciprocal rule no longer hold** [10], [18].
			- Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph
		- Previous researchers have proposed many methods to solve the navigation problem. The Social Force Model [19] is one of the representative methods that has been successfully applied and extended in different environments [7], [20], [21]. Reciprocal velocity obstacles (RVO), which consider communications with other agents, were proposed in multiagent navigation scenarios [2]. More recently, ORCA was proposed in [3]. It enables multiple robots to avoid collisions when navigating in a cluttered workspace. The main limitations of these model-based methods are that they **require tedious parameter selection** and that they may lead to **unnatural robot behaviors**, since they do not **fully capture real human behavior**.
		- Model-based approaches are typically extensions of multiagent collision avoidance algorithms, with additional parameters introduced to account for social interactions [7], [10]–[13]. For instance, to distinguish between human–human and human–robot interactions, the extended social forces model [11], [12] augments the potential field algorithm with additional terms that specify the repulsive forces (e.g., strength and range) governing each type of interaction. Model-based methods are designed to be **computationally efficient** as they often correspond to intuitive geometric relations; yet, it is **unclear whether humans do follow such precise geometric rules**. In particular, the **force parameters often need to be tuned individually**, and can **vary significantly for different pedestrians** [12]. Also, it has been observed that model-based methods can lead to **oscillatory paths** [2], [14].
			- Socially aware motion planning with deep reinforcement learning
	- Imitation learning / supervised learning
	  collapsed:: true
		- Supervised learning-based approaches are **purely data-driven and easy to use**, but require **laboriously collecting a representative set of expert demonstrations** to train the network [5], [20]–[24].
			- DRL-VO: Learning to Navigate Through Crowded Dynamic Scenes Using Velocity Obstacles
		- The other approach follows a different idea of learning navigation behavior methods by observing humans. Since the robot learns the model based on observations, it has the **advantage of adapting the special environments and improving its efficiency over time**. It has also **online computationally low calculations for predictions as long as learning happens offline**. The idea aims to transfer the human behavior model to the local planner by modeling human or crowd motions through human observations gathered from sensing functionalities of a robot using machine learning algorithms. Inverse reinforcement learning (IRL) is used for a guide robot in [16] to learn pairwise relative motions between a robot and a human by observing person walking. [17] offers extended Bayesian IRL to use for not only simple situations but also scalable to large domains using graph-based representation of task structure.
		- **Alternatively**, imitation learning aims to learn optimal policies from human demonstrations directly. In the context of robot navigation, previous work has used imitation learning to obtain policies from raw 2D laser data [22] or depth inputs [23] in a supervised way. Inverse reinforcement learning has also been applied to model human cooperative navigation behavior through a maximum entropy method [24], [25].
		- learning-based approaches aim to develop a policy that emulates human behaviors by matching feature statistics, such as the minimum separation distance to pedestrians. In particular, Inverse Reinforcement Learning (IRL) [15] has been applied to learn a cost function from human demonstration (teleoperation) [16], and a probability distribution over the set of joint trajectories with nearby pedestrians [2], [17]. Compared with model-based approaches, learning-based methods have been shown to **produce paths that more closely resemble human behaviors**, but often at a much **higher computational cost**. This is because **computing/matching trajectory features often requires anticipating the joint paths of all nearby pedestrians** [2], and might **depend on some unobservable information (e.g., pedestrians' goals)**. More importantly, since **human behaviors are inherently stochastic, the feature statistics calculated on pedestrians' paths can vary significantly from person to person**, and even run to run for the same scenario [2], [16]. This raises **concerns over whether such feature-matching methods are generalizable to different environments** [13]. **In short, existing works are mostly focused on modeling and replicating the detailed mechanisms of social compliance, which remains difficult to quantify due to the stochasticity in people's behaviors.**
			- Socially aware motion planning with deep reinforcement learning
		- With the success of deep learning in the computer vision area, many researchers started to apply learning-based approaches to other problems, including robot navigation. Unlike the traditional model-based approaches with multi-stage procedures, several recent works use deep neural networks to learn end-to-end control policies that generate steering commands directly from raw sensor data. Pfeiffer et al. [20] create a datadriven end-to-end motion planner that uses a convolutional neural network (CNN) to generate a linear and angular velocity from raw lidar data. Tai et al. [21] also use a CNN to select from one of five discrete robot control commands using raw depth camera data as input. Loquercio et al. [22] use a similar approach with raw camera image data to train a control policy that enables a drone to drive safely in the streets. Similarly, Kahn et al. [23] also use the raw camera image data to train an end-to-end learning-based mobile robot navigation system that can navigate in real-world environments with geometrically distracting obstacles. However, most of these end-to-end approaches only focus on static environments. For dynamic environments, Pokle et al. [24] use multiple CNN networks to learn multimodal high-level features from raw sensor data. A CNN-based local planner fuses these features to generate velocity commands. However, their learned feature-based policy was only tested in a relatively open simulated environment with no more than 3 moving pedestrians. For highly crowded dynamic environments with up to 50 moving pedestrians, our previous work [5] proposes a CNN-based policy that combined a short history of lidar data with kinematic data about nearby pedestrians.1 However, as we will show, the policy trained in a supervised setting is not as successful as the approach proposed in this work, **particularly when applied to new environments or crowd sizes**.
	- RL
	  collapsed:: true
		- **we use a novel deep reinforcement learning based (DRL) approach due to the complexity of the environments we want the robot to operate in, with 10's of pedestrians moving in dense crowds, which makes it difficult to design clear rules within a traditional model-based framework or to collect sufficiently representative training data to apply supervised learning techniques.**
		- Reinforcement learning-based approaches are **experience-driven and similar to human learning**, but **require carefully designing a reward function** [6], [26]–[41]. Although each type of approach has its own advantages and disadvantages, **we choose the reinforcement learning-based framework because it is difficult to manually design a general model or collect effective training data in uncontrolled and human-filled environments.**
			- DRL-VO: Learning to Navigate Through Crowded Dynamic Scenes Using Velocity Obstacles
		- Deep reinforcement learning algorithms learn policies while the robot interacts with the environment through **trial-and-error**. For robot navigation, recent work has used reinforcement learning methods to learn policies from **raw sensor inputs** [26] or **agent-level representations of the environment** [9], [10]. Learning from **raw sensor representation has the benefit that static and dynamic obstacles can be considered together through a single neural network**. However, **an agent level representation can provide a richer high-level representation of pedestrian intent that is difficult to extract from raw sensor information**. **One challenge is the varying crowd size**. Everett et al. [10] converted the state of a variable sized crowd to a fixed-length vector using an LSTM module that processed each pedestrian's state in descending order of their distance from the robot. However, the assignment of the importance according to distance is not always reasonable. For example, a pedestrian closely following a robot may be less important than a farther pedestrian in front of it. A recent work [9] adopted a self-attention module to assign different relative importances to different parts of the crowd. In our work, we infer the relative importance of neighboring humans to the robot by learning attention weights from gaze data collected from humans performing a crowd navigation task.
			- Robot Navigation in Crowds by Graph Convolutional Networks With Attention Learned From Human Gaze
		- Compared with supervised learning-based methods, DRL based approaches are more commonly used for navigation in dynamic environments. Using the proximal policy optimization (PPO) algorithm [25], Long et al. [26], [27] first propose a fully decentralized multi-robot collision avoidance framework using 2D raw lidar range data. Following this line of thought, Guldenring et al. [6] investigate the different state representations of 2D lidar data, and use the PPO training algorithm to train a human-aware navigation policy. Arpino et al. [28] present a multi-layout training regime that uses raw lidar data as its input to train an indoor navigation policy. Huang et al. [29] construct a multi-modal late fusion network to fuse raw lidar data and raw camera image data. Although these sensor-level approaches can quickly and easily generate control policies, they cannot distinguish between static or dynamic obstacles, nor can they utilize high-level information such as the positions and velocities of obstacles. To address the limitations of using only raw sensor data, many other works leverage information about the pedestrian motion to enable safe navigation in dynamic environments. Everett et al. [30]–[32] directly feed the relative position and velocity of pedestrians into the neural network, and generate socially aware collision avoidance policies for pedestrian-rich environments. Chen et al. [33] focus on jointly modeling human-robot and human-human interactions by a self-attention mechanism. Immediately afterwards, they also propose a relational graph learning network to infer robot-human interactions and predict their trajectories [34]. Similarly, another work [35] encodes the crowd state with a graph convolutional network (GCN) and predicts human attention. Recently, Liu et al. [36] use a decentralized structural-recurrent neural network (RNN) to model the interaction between the robot and pedestrians. **One major drawback of these agent-level approaches is that they are only suitable for solving crowded navigation problems in open spaces and ignore static obstacles and geometric constraints in the layout**. To solve this issue, Liu et al. [37] expand the work of [33] by adding additional static obstacle maps, but they need two parallel network models to handle the presence/absence of pedestrians. Sathyamoorthy et al. [38] expand the PPO training policy of [26] by using a late fusion network to combine raw lidar data with pedestrian trajectory predictions. Dugas et al. [39] use unsupervised learning architectures to predict and reconstruct future lidar latent states. However, **most of the above-described works only focus on exploiting the sensor perception information and its data representations, but ignore the reward function design**. Towards this, Xu et al. [40] propose a knowledge distillation reward term to encourage the robot to learn expert behaviors. Patel et al. [41] propose a square warning region-based reward function to encourage the robot to navigate in the direction opposite to the heading direction of obstacles. However, the effect of **knowledge distillation reward largely depends on the quality of the expert dataset**, and the **reward function based on the square warning region is too conservative, resulting in slow actions**.
		- robust
			- socially acceptable behaviours demands a trade-off between social comfort and other metrics of efficiency
		- human behavior modelling
			- group
			- gait, posture, head orientation
			- gaze
	- perceived Emotion / personal space
	  collapsed:: true
		- affect (the scientific term for emotions)
		- personal space
		- comfort zone
		- promexics
		- But, shape of personal space is incorrect
		- Social navigation has been extensively studied in the last decade and several theories and methods have been proposed since then (see [18], [33] and more recently [4] for deep reviews).The main idea is to create socially acceptable behaviors for robots during their navigation, what has been introduced as social mapping [3]. This **social mapping deals with the problem of human-aware robot navigation and considers factors like human comfort,sociability, safety and naturalness** [18]. More recently, in [14] the concept of behavioral mapping has been introduced, where the authors extend social mapping to a behavioral model acting as a mediator that facilitates seamless cooperation among the humans.
			- Socially aware robot navigation system in human-populated and interactive environments based on an adaptive spatial density function and space affordances
		- Under this prism, different works such as [23,24,45], have shown that the same proxemic zones that exist in human-human interaction can also be applied to human-robot interaction scenarios. A broad survey and discussion regarding the **social concepts of proxemics theory applied in the context of human-aware autonomous navigation** was presented in [33,34]. Most of these works define **areas where robot navigation is forbidden**, that is,when social robots plan to navigate, they must be aware of the permitted and forbidden actions in social spaces [33]. The works presented in [12,17,36,38] are among the most relevant in the literature regarding this problem. **However, these forbidden regions imposed by proxemics for robot navigation are not permanent,as several authors have pointed out, and can vary accordingly to different aspects**. Previous experience with the robot [39], or the functional noise of the robot [1] are examples of aspects that influence on these areas.
			- Socially aware robot navigation system in human-populated and interactive environments based on an adaptive spatial density function and space affordances
		- Most of social navigation algorithms are based on using a classic navigation algorithm, and therefore **adding social conventions and/or social constraints**. According to this paradigm, some authors have proposed models of social rules by using cost functions.In [13], for instance, the authors use a classical A∗ path planner in conjunction with social conventions, such as to pass humans on the right. In the Traberg et al.'s work [8], they use potential fields and a proxemics model. **Works like [21] demonstrates that navigation algorithms based on proxemic are not always the best choice, and there exist more attributes that provide in robot socially agreeable cruising. There exist other solutions for social navigation which use the detection of human intentions in order to model the social navigation**. In [32], authors propose the Modified Social Force Model (MSFM), basically a local navigation method where the path is able to be modified after analyzing the human intention. Other Social Force Model where used in [5] for robot interaction. Also, different works study learning navigation behaviors through different methods, such as inverse reinforcement learning[10,16,27], RTT planner [31] or maximum entropy learning methods[19].
			- Socially aware robot navigation system in human-populated and interactive environments based on an adaptive spatial density function and space affordances
		- When a robot plans the best path in human-populated environments, it must avoid passing between two people talking or getting inside the field of view of the people when they are observing a particular object. Social mapping is an interesting concept recently introduced in the robotics community in order to manage the shared space between humans and robots. In [30] it is proposed a framework that can model context-dependent human spatial interactions, encoded in the form of a social map. The social map is obtained by solving a learning problem using Kernel Principal Component Analysis (KPCA), and later the social borders are calculated as isocontours of the learned implicit function. This work is extended in [29], where authors suggest a skew-normal probability density in order to model the social space. The authors in [22] use a **perceptual model that takes into account the relative pose between human and robot, the human gestures and the speech volume for building the social space**. Recently, in [15] authors present a **human-oriented robot navigation strategy where the human space is modeled according to proxemics theory**. In summary, the number of works that have incorporated this notion of personal space model in the path planning step has increased in the last years [4]. The work presented in this paper is also based on proxemics theory. Unlike other social navigation algorithms that only use RRT or similar planner, this approach uses a PRM-RRTpath planner plus the Elastic Band Path Optimization as the navigation stack. In this paper, personal spaces define forbidden areas for robot navigation. These forbidden regions allow to update the graph of free space and directly re-adapt the path planned by the robot during navigation, which is a significant advantage that similar approaches lack.
			- Socially aware robot navigation system in human-populated and interactive environments based on an adaptive spatial density function and space affordances
		- Humans navigating among crowds follow social norms relating to the speed of movement or personal space. In particular, **we tend to observe the emotions displayed by others and adjust our paths in response**. Correspondingly, there is much prior work on having mobile robots navigate among humans in a socially-aware manner [38], [24], [36], [16], [25]. Some navigation algorithms generate socially compliant trajectories by predicting the pedestrian movement and forthcoming interactions [25] or use modified interacting Gaussian processes to develop a probabilistic model of robot-human cooperative collision avoidance [52]. Vemula et al. [54] proposed a trajectory prediction model that captures the relative importance of each pedestrian in a crowd during navigation. Other methods tend to model interactions and personal space for human-aware navigation [1] or use learning-based approaches to account for social conventions in robot navigation [29], [39], [42]. Many explicit models have been proposed for social constraints to enable person acceptable navigation [51], [22]. However, **these methods do not take into account psychological constraints or emotions of the pedestrians**.
		- For years, extensive research has been done for obstacle avoidance in a safe and optimal perspective. Recently, studies have been focused more on **robots' sociability**. In previous work [6–9], robots' sociability is mainly created from the **perspective of imitating humans**. However, in the navigation process, there is **hardly interactive behavior between the robot and humans**, and the **robot's behaviors are not adaptive to human's emotion**. One example can be found in [10] where **Dynamic Social Zone** is proposed to describe social space by considering human states such as position, orientation, motion and hand poses.
			- Interactive Navigation of Mobile Robots Based on Human’s Emotion
		- The other approach is to refer to **proxemics theory-based costmaps**. ROS costmap library1 provides a layered costmap plugins representation and allows to work with separate layers (twodimensional grids) for static map, obstacle, inflation and other user specified layers (e.g. socially aware costmaps). For example, we can **produce a dynamic human-aware proxemic costmap** layer (**appropriate distance to people**). It subscribes w**here people are and alters costmaps with adding gaussian costs around the detected dynamic or static person** so that the robot navigate among humans in a collision free manner by respecting their personal or social zones (proxemic concerns) [12,13]. Using this representation, one can also easily incorporate predicted human motion trajectories as a series of layers populating the cost map accordingly [14] or **emotion-based proxemic constraints** [15]. However, this approach becomes costly when the number of people in the environment or map size increases due to large memory requirements. Moreover, in case the cost maps of one or more dynamic/static people around the robot **block the possible paths of the robot, the robot might ''freeze", and can not move although there is available space for action**.
			- Social navigation framework for assistive robots in human inhabited unknown environments
	- perceived psychological state
		- emotion / affect
			- Face and speech data have been widely used to perceive human emotions. Prior methods that use faces as input commonly track action units on the face such as points on the eyebrow, cheeks and lips [16], or track eye movements [39] and facial expressions [33]. Speech-based emotion perception methods use either spectral features or prosodic features like loudness of voice, difference in tones and changes in pitch [24]. With the rising popularity of deep learning, there is considerable work on developing learned features for emotion detection from large-scale databases of faces [51, 53] and speech signals [12]. Recent methods have also looked at the crossmodality of combined face and speech data to perform emotion recognition [1]. In addition to faces and speech, physiological signals such as heartbeats and respiration rates [55] have also been used to increase the accuracy of emotion perception. Our approach for emotion perception from walking videos and gaits is complimentary to these methods and can be combined.
				- STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits
				  id:: 654e834c-911e-494f-987e-8742b1bd9d0d
			- There exists a substantial amount of research that focuses on identifying the emotions of humans based on body posture, movement, and other non-verbal cues. Ruiz-Garcia et al. [28] and Tarnowski et al. [29], use deep learning to classify different categories of emotion from facial expressions. The approach by [8] uses multiple modalities such as facial cues, human pose and scene understanding. Randhavane et al. [30], [31] classify emotions into four classes based on affective features obtained from 3D skeletal poses extracted from human gait cycles. Their algorithm, however, requires a large number of 3D skeletal key-points to detect emotions and is limited to single individual cases. Bera et al. [32], [33] classify emotions based on facial expressions along with a pedestrian trajectory obtained from overhead cameras.
				- ProxEmo: Gait-based Emotion Learning and Multi-view Proxemic Fusion for Socially-Aware Robot Navigation
			- multi modal
				- gait
				- gesture
			- context aware
		- comfort
	- As novelty, prediction of future personal space
		- Pedestrian intent / trajectory Prediction / forecasting
			- spatial arrangement of multi humans
				- Social GAN (based on its literature review)
			- group
			- gait, posture, head orientation
			- gaze
			- Most of social navigation algorithms are based on using a classic navigation algorithm, and therefore **adding social conventions and/or social constraints**. According to this paradigm, some authors have proposed models of social rules by using cost functions.In [13], for instance, the authors use a classical A∗ path planner in conjunction with social conventions, such as to pass humans on the right. In the Traberg et al.'s work [8], they use potential fields and a proxemics model. **Works like [21] demonstrates that navigation algorithms based on proxemic are not always the best choice, and there exist more attributes that provide in robot socially agreeable cruising. There exist other solutions for social navigation which use the detection of human intentions in order to model the social navigation**. In [32], authors propose the Modified Social Force Model (MSFM), basically a local navigation method where the path is able to be modified after analyzing the human intention. Other Social Force Model where used in [5] for robot interaction. Also, different works study learning navigation behaviors through different methods, such as inverse reinforcement learning[10,16,27], RTT planner [31] or maximum entropy learning methods[19].
				- Socially aware robot navigation system in human-populated and interactive environments based on an adaptive spatial density function and space affordances
			- Recently, researchers have studied how interactive factors affect agents' trajectory plans, like social interaction [1,15,36,60] and scene interaction [31,56]. The modeling of agents' trajectories also matters how the trajectory prediction networks perform. Alahi et al. [1] treat this task as a sequence generation problem, and they employ LSTMs to model and predict pedestrians' positions in the next time step recurrently. A series of works have also introduced Graph Neural Networks (GNNs), e.g. Graph Attention Networks (GATs) [15,22,27] and GCNs [4,36], to handle interactive factors when forecasting. Moreover, the attention mechanism has been employed [51,55,60] to focus on the most valuable interactive targets to give reasonable predictions. With the success of Transformers [50] in sequence processing such as natural language processing, researchers [13,58] have employed Transformers to obtain better feature representations. Some researchers address agents' uncertainty and randomness by introducing generative models. Generative Adversarial Networks (GANs) are employed in [14,43,22] to generate multiple stochastic trajectories to suit agents' various future choices. Some works like [17,45] use the Conditional Variation AutoEncoder (CVAE) to achieve the similar goal.
				- View Vertically: A Hierarchical Network for Trajectory Prediction via Fourier Spectrums
			- Moreover, research efforts on using human motions and predicting human future behavior are also introduced. [18] extends the timed elastic band approach by proposing a **cooperative navigation planner** that predicts the possible future trajectories of nearby humans and accordingly generates a socially acceptable plan for the robot using optimization based framework. RRT algorithm navigation strategy is extended by [19] to **gain the ability of respecting proxemics and social conventions** (specifically conversational interactions of o-space between humans). In addition to that, approaches based on fuzzy logic/control are also used in the **recognition of the human's intentions**. The robot tries to recognize the human intention with relative speeds and heading angle from which appropriate fuzzy control rules are presented in [20].
			- Some studies have highlighted that purely reactive obstacle prevention techniques may not be sufficient for solving navigation problems in dynamic environments [59], [60].
			- In social robotics, an **accurate prediction of pedestrian trajectories plays a significant role in robot decisions in terms of reactive response, navigation planning**, etc. For simplicity and ease of computation for navigational robots, the problem of pedestrian intention prediction is largely modeled as a trajectory prediction problem. Recurrent Neural Network based architectures are widely used for predicting pedestrian trajectories [19], [20], [21]. [22] use a Graph Convolution method to predict the trajectories and showed that Temporal Graph Convolutions are much better at predicting pedestrian trajectories compared to recurrent networks. Most recurrent networks for trajectory prediction leverages some form of attention mechanism to improve the trajectories. [21], [19] uses a history of observed trajectories with either predicted future trajectory or location around pedestrians to predict the intent. [20] provide skeletal joint kinematics as attention for trajectory prediction. These models, one way or the other, solely depend on the trajectory and kinematics of joints for predicting the intent, and there is **no attention given to the emotional state of the pedestrians**.
			- Utilizing the recent advancements in pedestrian trajectory prediction [19]–[22], one line of work **uses the predicted human states to compute the transition probabilities of MDP and then plans optimal robot actions with search trees** [11], [23], [24]. However, the computation cost of tree search grows exponentially with the size of robot action space. Thus, these methods usually choose discrete and small action spaces, which leads to less natural robot trajectories. Another line of work **uses the one-step predictions as observations of model-free RL policies** [12], [25]. Although the action space can be large and continuous, one-step predictions only capture the instantaneous velocities instead of intentions of pedestrians. Our method **makes predictions for several timesteps to capture the long-term intents of pedestrians** and modify the reward function based on predictions so that the robot is intention-aware. Although some other works attempt to predict the long-term goals of pedestrians to aid planning, the set of all possible goals is finite and small, which limits the generalization of these methods [13], [26]. In contrast, for our method, the goals of pedestrians can be any position in a continuous two-dimensional space.
				- Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph
			- prediction based on gait
				- [20] [21] provide skeletal joint kinematics as attention for trajectory prediction. These models, one way or the other, solely depend on the trajectory and kinematics of joints for predicting the intent
					- EWareNet: Emotion Aware Human Intent Prediction and Adaptive Spatial Profile Fusion for Social Robot Navigation.
				- We introduce a novel approach using transformers to predict the full-body pedestrian intent or behavior in the form of trajectory/gaits based on historical gait sequences.
					- EWareNet: Emotion Aware Human Intent Prediction and Adaptive Spatial Profile Fusion for Social Robot Navigation.
	- Proactive / cooperative interaction
	- Preference learning
	  collapsed:: true
		- Active preference or feedback learning [16], [17], which relies on human feedback rather than demonstrations to provide corrective and adaptable instructions to guide the learning process, can serve as a good alternative for addressing the above-described challenges. Such interactive reinforcement learning can tailor robot behaviors to human preference naturally, without reward engineering and exploitation. In addition, it does not require and therefore is not limited by expensive human demonstrations. However, achieving good performance with active preference learning does require sufficiently frequent human feedback. Thus, it is essential to improve feedback efficiency so as to reduce the requisite human workload.
			- Feedback-efficient Active Preference Learning for Socially Aware Robot Navigation
		- Our approach, feedback-efficient active preference learning or FAPL, can **encode human comfort and expectation into a reward model and then into robot policy**. To improve feedback efficiency, we introduce hybrid experience learning, which enables a human teacher to provide more critical feedback in the process of active reward learning. In contrast to existing RL methods, FAPL distills the reward model from human preferences rather than having it handcrafted, covers social compliance more intuitively and comprehensively, and avoids reward exploitation. Also, distinct from IRL methods, FAPL introduces expert intelligence without suffering from expensive, noisy, and scarce human demonstrations, nor from extensive feature engineering.
			- Feedback-efficient Active Preference Learning for Socially Aware Robot Navigation
		- On the other hand, fewer studies have been conducted to improve the model from the policy learning perspective. Most of them either rely on handcrafted reward function or inverse RL for policy learning. However, the handcrafted reward functions are hard to quantify complex and broad social norms and can result in the reward exploitation problem that leads to unnatural robot behaviors [11]. Moreover, while inverse RL can introduce human expectations to robot policy through demonstrations, it suffers from expensive and inaccurate demonstrations as well as extensive feature engineering. To address these limitations, [11] proposed an active preference learning to tailor a reward model by human feedback, leading to more preferred and natural robot actions.
			- NaviSTAR: Socially Aware Robot Navigation with Hybrid Spatio-Temporal Graph Transformer and Preference Learning
		- We leverage off-policy learning and preference learning to train a robot policy that considers social norms and human expectations
			- NaviSTAR: Socially Aware Robot Navigation with Hybrid Spatio-Temporal Graph Transformer and Preference Learning
- Methodology
	- We perform a multi-stage training of our policy network to aid policy convergence.
	- setup
		- Simulation Environment: Fig. 6 illustrates our 2D simulator based on [7], [9]. And the kinematics of environment dynamics is simplified by ∆t from [6], and human policies are developed with ORCA [24]. We assume that the robot is invisible to each human in the environment to optimize navigation behavior. The robot's action is defined as at = [vx, vy], and its FOV is set from 0° to 360°. We train and test the simulation in an open space with dimensions of20 m × 22 m, where humans are randomly generated on a circle with a radius of 8 m.
		- Our 2D environment simulates a scenario where a robot navigates through a dense crowd in a 12m × 12m space, as shown in Fig. 3. Our simulation captures more realistic crowd navigation scenarios than previous works in two aspects [3], [10]. First, our robot sensor has a limited circular sensor range of 5m, while the previous works unrealistically assume that the robot has an infinite detection range. Second, the maximum number of humans can reach up to 20, leading to a denser and more interactive human crowd.
		- In each episode, the starting and goal positions of the robot and the humans are randomly sampled on the 2D plane. To simulate a continuous human flow, humans will move to new random goals immediately after they arrive at their goal positions. All humans are controlled by ORCA and react only to other humans but not to the robot. This invisible setting prevents our model from learning an extremely aggressive policy in which the robot forces all humans to yield while achieving a high reward.
		- We use holonomic kinematics for simulated robot and humans, whose action at time t consists of the desired velocity along the x and y axis, at = [vx, vy ]. The action space of the robot is continuous with a maximum speed of1m/s. We assume that all agents can achieve the desired velocities immediately, and they will keep moving with these velocities for the next ∆t seconds.
		- The first environment simulates humans with constantly changing intents and different traits with the following randomizations: First, all humans occasionally change their goals to other random positions within an episode; Second, each human has a random maximum speed vmax ∈ [0.5, 1.5]m/s and radiusρ ∈ [0.3, 0.5]m.
			- the randomizations in the first environment pose extra challenges for prediction and decision making
	- Environment Setup
	  id:: 65548831-7b4d-4deb-97d4-4b88a3f52f19
		- {{renderer :wordcount_}}
			- Training and testing were conducted in a 2D environment that simulates a scenario where a social robot navigates through a dense crowd in a 20m × 20m space, as illustrated in Fig. 3. To emulate the deployment of the robot in the real world, the sensing range of the robot's sensor is limited to 5m with field of view (FOV) of 360°. The motion of the robot are designed as holonomic kinematics, with continuous action space and maximum speed of 1 m/s.
			- At the beginning of every episode, the initial and goal positions of the robot and the pedestrians are randomly sampled in the 2D environment. To simulate a continuous human flow, humans will move to new random goals immediately after they arrive at their goal positions. Moreover, to have a more realistic crowd navigation scenarios, throughout an episode, the pedestrians will be constantly altering their intents by occasionally changing their goals to other random coordinates within an episode. Besides that, there will also be random changes in the emotion and maximum speed of every individuals within an episode. As a result, this randomization in the humans' behaviors and intentions would pose greater challenges to the robot, in terms of human intent prediction and decision making during navigation. Furthermore, the motion of the humans are computed by ORCA [1], which their policy would react only to other people but not to the robot. This invisible configuration avoids the model from learning an extremely aggressive policy in which the robot will force all humans to clear a path for the robot to approach its goal with the shortest route.