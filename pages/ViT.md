alias:: Vision Transformer

- need very large dataset for pretraining
  ![image.png](../assets/image_1696052639360_0.png)
- **split image into patches**
  ![image.png](../assets/image_1696053221960_0.png)
  [[hyperparameter]]
  ![image.png](../assets/image_1696053325914_0.png)
- [[vectorization]]
  flatten a matrix to a vector
  ![image.png](../assets/image_1696052713618_0.png)
- [[positional encoding]] is needed because [[Transformers]] doesn't capture positional relationship
- the transformer encoder network may consist of multiple blocks of [[transformer/encoder]] 
  ![image.png](../assets/image_1696053113376_0.png)