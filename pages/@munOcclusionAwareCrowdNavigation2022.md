links:: [Local library](zotero://select/library/items/4F98EFRF), [Web library](https://www.zotero.org/users/10791428/items/4F98EFRF)
authors:: [[Ye-Ji Mun]], [[Masha Itkina]], [[Shuijing Liu]], [[Katherine Driggs-Campbell]]
tags:: [[Computer Science - Human-Computer Interaction]], [[Computer Science - Machine Learning]], [[Computer Science - Robotics]], [[open-source]], [[reading]], [[literature-review]]
date:: [[Mon, 07.11.2022]]
item-type:: [[preprint]]
title:: @munOcclusionAwareCrowdNavigation2022

- [[Abstract]]
	- Autonomous navigation in crowded spaces poses a challenge for mobile robots due to the highly dynamic, partially observable environment. Occlusions are highly prevalent in such settings due to a limited sensor field of view and obstructing human agents. Previous work has shown that observed interactive behaviors of human agents can be used to estimate potential obstacles despite occlusions. We propose integrating such social inference techniques into the planning pipeline. We use a variational autoencoder with a specially designed loss function to learn representations that are meaningful for occlusion inference. This work adopts a deep reinforcement learning approach to incorporate the learned representation for occlusion-aware planning. In simulation, our occlusion-aware policy achieves comparable collision avoidance performance to fully observable navigation by estimating agents in occluded spaces. We demonstrate successful policy transfer from simulation to the real-world Turtlebot 2i. To the best of our knowledge, this work is the first to use social occlusion inference for crowd navigation.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/2210.00552) {{zotero-imported-file YQ2N2NC3, "2210.html"}}
	- [Mun et al. - 2022 - Occlusion-Aware Crowd Navigation Using People as S.pdf](https://arxiv.org/pdf/2210.00552.pdf) {{zotero-imported-file 8H843RW8, "Mun et al. - 2022 - Occlusion-Aware Crowd Navigation Using People as S.pdf"}}